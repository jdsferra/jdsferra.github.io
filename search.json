[
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog",
    "section": "",
    "text": "Musical Scores as Data Visualizations\n\n\n\n\n\n\nData Visualization\n\n\nMusic\n\n\n\nWell, wait, are they?\n\n\n\n\n\nDec 5, 2024\n\n\nJoe Sferra\n\n\n\n\n\n\n\n\n\n\n\n\nPizza and Chatbots: Wouldn’t It Be Loverly!- Meeting ELIZA\n\n\n\n\n\n\nPython\n\n\nAI\n\n\n\nSharing about a data event hosted at SUNY-Old Westbury.\n\n\n\n\n\nNov 14, 2024\n\n\nJoe Sferra\n\n\n\n\n\n\n\n\n\n\n\n\nMaking a Twelve-Tone Matrix Generator in Python\n\n\n\n\n\n\nPython\n\n\nMusic\n\n\n\nRecreating a tool I used in the music theory classroom with Python.\n\n\n\n\n\nNov 7, 2024\n\n\nJoe Sferra\n\n\n\n\n\n\n\n\n\n\n\n\nPython, Pizza and Trust the Process(ing) Wrap-up\n\n\n\n\n\n\nPython\n\n\n\nSharing about a fun data event hosted at SUNY-Old Westbury.\n\n\n\n\n\nOct 31, 2024\n\n\nJoe Sferra\n\n\n\n\n\n\n\n\n\n\n\n\nPublication Announcement!\n\n\n\n\n\n\nEducation\n\n\nMusic\n\n\n\nI collaborated on writing a chapter of a book on music education that is now published.\n\n\n\n\n\nOct 23, 2024\n\n\nJoe Sferra\n\n\n\n\n\n\n\n\n\n\n\n\nACCET Faculty Professional Development Day Wrap-Up\n\n\n\n\n\n\nEducation\n\n\nAI\n\n\n\nSharing about presenting at a professional development day last week.\n\n\n\n\n\nOct 16, 2024\n\n\nJoe Sferra\n\n\n\n\n\n\n\n\n\n\n\n\nYou’re Not Behind, You’re Not Alone\n\n\n\n\n\n\nEducation\n\n\n\nSome advice and words of encouragement to people studying in an online bootcamp.\n\n\n\n\n\nSep 26, 2024\n\n\nJoe Sferra\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Joe Sferra",
    "section": "",
    "text": "Data professional finishing my fellowship at NYC Data Science Academy. I am working on a capstone project to provide a report card on the health of a business via documenting executive turnover. Experienced in SQL, Python, and R.\nI recently completed an internship at Articulate.AI that involved collaborating on the redesign of a no-code chatbot interface and produced a series of demo videos. I analyzed chatbot logs to suggest revisions to clients’ bots and assisted in the onboarding process. I am now on a contract there as a Pre-Sales Data Scientist.\nI grew up in Ohio and earned a PhD in music composition at SUNY-Stony Brook. Over eight years, I taught music theory and composition at Stony Brook, Earlham, Vassar, SUNY-Potsdam, and the Cleveland Institute of Music. I presented at six academic conferences, published three peer-reviewed works, and was featured as a clarinetist on two professional albums. I now live in the New York metropolitan area and am seeking full-time roles as an analyst or sales engineer.\nMy background as a musician and teacher means that I have a unique approach to problem-solving that combines creativity and analytical skills. I have a proven record of translating complex ideas into concrete solutions for diverse audiences. Brainstorming and collaborating are some of my favorite things to do.\nCheck out the portfolio tab, which includes my data analytics and data science projects with links to code, deeper blog posts about the projects, and videos discussing my approach. I’m looking forward to populating my personal blog here with more thoughts about data, education, creative problem solving, statistics, coding, music, and more!"
  },
  {
    "objectID": "posts/2024-10-31-Westbury-Meetup/index.html",
    "href": "posts/2024-10-31-Westbury-Meetup/index.html",
    "title": "Python, Pizza and Trust the Process(ing) Wrap-up",
    "section": "",
    "text": "Last night, I attended the first in a series of yearly events hosted by SUNY-Old Westbury. I found it through the Long Island Data Analytics Meetup Group and I’m really glad I went. After we got some pizza and hooked up to the WiFi, Professor Ashok Basawapatna took us through a great project on baseball pitches that he’s been working on.\nThe project involved processing data from pybaseball. I was surprised at the granular level of detail that the dataset had about every pitch thrown in an MLB game. Dr. Basawapatna mentioned that this attention to detail really surged in the wake of the success of the 2002 Oakland Athletics, AKA the “Moneyball” season. It seemed like you could reanimate the entire game given all the details in the data, but we concentrated on pitches.\nBy taking information about the ball’s starting position and velocity in three dimensions, along with its average acceleration, we could approximate any pitch’s trajectory. While the dataset measures all these parameters with respect to home plate, we had to do some 3-D math in our heads in order to make these same details make sense graphically. But in the end, we got something! By the end of the hour and a half, we could take any pitch thrown in an MLB game and reconstruct what it would be like to be the catcher waiting behind home.\n\n\n\nOnce I figure out how to get GIFs going on this page it’s going to be awesome!\n\n\nNot only was the presentation really cool, it was also great to see a big group of people together in a conference room getting excited about this stuff. We ended up having an impromptu meeting of people interested in reviving the PyData Long Island chapter too, so stay tuned on the Meetup page if you’re interested!"
  },
  {
    "objectID": "posts/2024-09-26-notbehind-notalone/index.html",
    "href": "posts/2024-09-26-notbehind-notalone/index.html",
    "title": "You’re Not Behind, You’re Not Alone",
    "section": "",
    "text": "During my career as a music theory professor, I saw the same freshmen in my classroom five days a week. Our classroom, inevitably, became the site not just of learning a difficult subject at a fast pace, but also of discussions about what strategies could help you do that. As a Data Science Fellow at NYCDSA, I’ve continued to rely on these strategies and wanted to share some of them with you as you a coding bootcamp. Writing these thoughts out, I found all of them revolving around two major ideas: 1. You’re not behind. 2. You’re not alone."
  },
  {
    "objectID": "posts/2024-09-26-notbehind-notalone/index.html#youre-not-behind",
    "href": "posts/2024-09-26-notbehind-notalone/index.html#youre-not-behind",
    "title": "You’re Not Behind, You’re Not Alone",
    "section": "You’re Not Behind",
    "text": "You’re Not Behind\nWhen you first see the extent of a bootcamp curriculum, you may feel overwhelmed. It has to be that wide to address all the foundational knowledge for today’s tech stacks and job market. With so much to learn, it’s easy to feel like you are always behind.\nI’ve discovered in my chats with former and current boot campers that everyone feels behind at some point. The truth is that while everyone in a cohort sometimes feels behind, they are also ahead of and alongside each other in various ways. These differences come from our diverse backgrounds, bringing prior strengths and skills that contribute to our understanding of data science differently. Virtual cohorts allows a great diversity of backgrounds in your community, and we can all learn from each other.\nAfter you start, you’ll find that your background will help you grasp some of the lessons relatively easily. Whether it’s the stats, the coding, domain knowledge, or communication skills, your experiences will help you pick up on certain parts of the curriculum more quickly than others. The others in your cohort will feel themselves as behind you at some point in the program, just like when you feel behind them. That we don’t have the same talents doesn’t mean the ones we have are any less valuable. As a musician, I always felt like I couldn’t play as fast and as high on my clarinet as my peers, but I could learn songs by ear and improvise better than a lot of them. In the same way, you’ll find aspects of the curriculum where you shine as long as you keep at it!\nMake the most of the experience and strike the right balance between feeling behind and feeling like you already know the material. When a session feels too advanced, think of it as a sort of heads-up about vocabulary and concepts that will come up in your career. When more basic classes feel too easy, think of it as a chance to solidify what you’ve been learning.\nI confided in NYCDSA’s director that I felt worried about falling behind in the program, and she comforted me by encouraging me to reframe my “timeline” from the weeks of the bootcamp to time I needed for “learning data science well and using it in my new career”. On that path, none of us are behind."
  },
  {
    "objectID": "posts/2024-09-26-notbehind-notalone/index.html#youre-not-alone",
    "href": "posts/2024-09-26-notbehind-notalone/index.html#youre-not-alone",
    "title": "You’re Not Behind, You’re Not Alone",
    "section": "You’re Not Alone",
    "text": "You’re Not Alone\nOnline instruction formats allow incredible flexibility and global collaboration. It’s easy to feel isolated, though, and that feeling can depress you and slow your learning. That’s why I urge you to capitalize on the synchronous portions of your program like the office hours and meetings with mentors. Be proactive about coming to live sessions. Turn your camera on, say “Hi”, ask questions, and message people who attended. Reaching out helps you feel connected and human as you learn, and the people at these sessions may become collaborators, coworkers, or friends in the coming years. Nearly everyone I’ve reached out to for advice on domain knowledge or help with a project has been willing to meet and chat.\nHelping out doesn’t necessarily mean teaching: it can just mean lending support. For example, I joined a study group that doesn’t even talk about the material; we just come together virtually on Zoom with our cameras on to keep us motivated and focused. You’re less likely to allow yourself to procrastinate if you’ll get caught! Even in a group like that, I know that I’m not alone and that I have people I can root for as they cheer me on, too.\nIf you keep at the front of your mind that you’re neither behind nor alone, you’ll be set up for staying on track. These are long-term goals, so think about where you want to end up and stick with it. Happy studying!"
  },
  {
    "objectID": "posts/2024-11-07-Matrix-Generator/index.html#meeting-the-matrix",
    "href": "posts/2024-11-07-Matrix-Generator/index.html#meeting-the-matrix",
    "title": "Making a Twelve-Tone Matrix Generator in Python",
    "section": "Meeting the Matrix",
    "text": "Meeting the Matrix\nThe twelve-tone matrix is a tool that most college music students have run into at least once in their lives during a music theory course. For a lot of them, it becomes the bane of their existence, as it relies on an understanding of math that they haven’t used much. To add insult to injury, matrices are used for atonal music, the kind of music that isn’t always pleasant to listen to! I thought that by coding a matrix generator out in Python, I could atone for subjecting former students to this technique and learn a little something myself.\nTo understand the matrix, we have to understand a little bit about music in the early twentieth century. At that time, musicians were reaching out to find new musical techniques to express themselves and their feelings about the world around them. Many felt adrift in the wake of conflicts like World War I, and to mirror that “adrift-ness” in their music, they abandoned the idea of tonality, or a central pitch that feels like “home” or the point of arrival in a piece of music. One technique they used to replace tonality (or to achieve “atonality”) was to use a “tone row”, a sequence of all 12 pitches in the chromatic scale, as their new “home”. The tone row gave them the opportunity to make music with wild new sounds and harmonies, but also some kind of “home” (even if it’s a whole lot harder to hear!). This row could be the basis for melodies, harmonies, and all the pitch decisions in a style of music that we call dodecaphonic, or 12-tone music.\nRuth Crawford Seeger’s String Quartet 1931 is a beautiful piece based on tone rows!"
  },
  {
    "objectID": "posts/2024-11-07-Matrix-Generator/index.html#pitch-class-space",
    "href": "posts/2024-11-07-Matrix-Generator/index.html#pitch-class-space",
    "title": "Making a Twelve-Tone Matrix Generator in Python",
    "section": "Pitch Class Space",
    "text": "Pitch Class Space\nThis isn’t the place where we can learn all of the theory that we need to know to approach this, but I will try to hit a couple of the big concepts so that you can dip your toes in. Dodecaphonic music relies on two types of equivalence:\n\nOctave Equivalence\nAn F# on a keyboard is an F# everywhere. Two notes that have the same note name, but in different octaves, are effectively the same.\n\n\nEnharmonic Equivalence\nAn F# is the same as a Gb. Two notes that would be on the same spot on the keyboard, but are spelled differently, are effectively the same.\nTaking these two assumptions together, atonal music now exists in pitch class space, a theoretical space like a clock’s face. If you go above or below the range of 0 to 11, it flips back around into that range. If you go two past 11, you get 1. If you start moving below zero, say to -5, it flips back around to being 7.\n\nSo before we start building our matrix, we need to express pitches with numbers in pitch-class space. Think about this as the ground rules for our calculator. Here’s a function in Python:\n\ndef modconvert(num):\n  if num &gt;= 0 and num &lt; 12:\n    return num\n  else:\n    return num % 12\n\nfor num in range(-6, 0):\n  print(f\"{num} modconverts to {modconvert(num)}\")\nfor num in range(12, 19):\n  print(f\"{num} modconverts to {modconvert(num)}\")\n\n-6 modconverts to 6\n-5 modconverts to 7\n-4 modconverts to 8\n-3 modconverts to 9\n-2 modconverts to 10\n-1 modconverts to 11\n12 modconverts to 0\n13 modconverts to 1\n14 modconverts to 2\n15 modconverts to 3\n16 modconverts to 4\n17 modconverts to 5\n18 modconverts to 6\n\n\nOk, so now we’re in pitch class space! We’re going to slap this conversion function on basically all the operations we do in the rest of the generator."
  },
  {
    "objectID": "posts/2024-11-07-Matrix-Generator/index.html#row-forms",
    "href": "posts/2024-11-07-Matrix-Generator/index.html#row-forms",
    "title": "Making a Twelve-Tone Matrix Generator in Python",
    "section": "Row Forms",
    "text": "Row Forms\nSo you may be thinking to yourself:\n\n“WHOA this music only uses one sequence of pitches the whole time? Wouldn’t that get boring?”\n\nThe answer is YES. That’s why the twelve-tone matrix exists. It’s a way to give one row a bunch of transformations to use as the basis of the composition. These transformations imitate techniques from earlier classical music: transposition, inversion, and retrograde.\n\nPrime, Inversion, Retrograde, Retrograde Inversion\nPrime forms represent the original row, but transposed. The difference between the index numbers represents their difference in half steps. In the matrix, read left to right.\nInversion forms represent the original row, but inverted. If you measure the intervals of a prime row in pitch class space and then mirror them (go left from the first number instead of right), you get the inversion forms. Read top to bottom.\nRetrograde is prime read in reverse. Notice the numbering convention. Read right to left.\nRetrograde Inversion is the retrograde reading of the inversion. Read bottom to top. Note: not the inversion of the retrograde!\n\n\nExpressing Row Forms in Python\nMy experience so far with learning data structures and algorithms is that you’re always trying to solve problems with the fewest number of calculations that you can possibly use. Don’t be inefficient. I really hope we don’t have to do all 48 calculations for this thing! And in fact we don’t! We’re going to do 12 transpositions of the original row and have them printed out to represent the whole matrix.\nThis means we have to take a few steps in Python now. Let’s say that we’re going to take in a list of twelve integers as the prime row, numbered 0-11. We’re going to need to transpose this row and measure by how far we have to transpose it.\nLet’s do the first part, transposing a row.\n\n# Takes in a row and transposes every pitch class \n# By the same interval (opci- hours forward on the clock).\n# Prints how it should look in the matrix\n\ndef transpose_print (row, opci):\n    transposed = [modconvert(x + opci) for x in row]\n    \n    newrow = f'P{transposed[0]} {transposed} R{transposed[0]}'\n    \n    # Naming convention to tighten matrix's looks up\n    print(newrow.replace('10', 'T').replace('11', 'E'))\n\nmyrow = [2, 11, 6, 5, 4, 3, 0, 8, 9, 7, 1, 10]\ntranspose_print(myrow, 3)\n\nP5 [5, 2, 9, 8, 7, 6, 3, E, 0, T, 4, 1] R5\n\n\nOk, so this looks like most of the lines of our matrix, so we’re getting close! We can express the matrix as a series of transpositions of the prime row. Now we need to measure by how far we have to transpose. I’m going to make a list called “Torder” or transposition order. It will be twelve numbers long, representing all the transpositions we’ll need to do, and they will represent inversions of the intervals in the original row.\nBefore you look at the “Torder” function below, try to imagine what Torder will look like for myrow.\n\nmyrow = [2, 11, 6, 5, 4, 3, 0, 8, 9, 7, 1, 10]\n\ndef make_torder(row):\n    # Creates the list of intervals by which \n    # You need to transpose and print the prime row\n    # First el is always 0\n    Torder = [0]\n    \n    # Append inversion of distance between each element and first element\n    for x in range(1,12):\n        i = modconvert(row[0] - row[x])\n        Torder.append(i)\n    \n    return Torder\n\ny = make_torder(myrow)\nprint(y)\n\n[0, 3, 8, 9, 10, 11, 2, 6, 5, 7, 1, 4]\n\n\nFiguring out this order is a bit tougher, so don’t worry if you don’t have this totally down in your head yet."
  },
  {
    "objectID": "posts/2024-11-07-Matrix-Generator/index.html#the-code-solution",
    "href": "posts/2024-11-07-Matrix-Generator/index.html#the-code-solution",
    "title": "Making a Twelve-Tone Matrix Generator in Python",
    "section": "The Code Solution",
    "text": "The Code Solution\n\n# Helper functions we have built so far\ndef modconvert(num):\n  if num &gt;= 0 and num &lt; 12:\n    return num\n  else:\n    return num % 12\n\ndef transpose_print (row, opci):\n    transposed = [modconvert(x+opci) for x in row]\n    \n    newrow = f'P{transposed[0]} {transposed} R{transposed[0]}'\n    \n    # Naming convention to tighten matrix's looks up\n    print(newrow.replace('10', 'T').replace('11', 'E'))\n    \ndef make_torder(row):\n    # Creates the list of intervals by which \n    # You need to transpose and print the prime row\n    # First el is always 0\n    Torder = [0]\n    \n    # Append inversion of distance between each element and first element\n    for x in range(1,12):\n        i = modconvert(row[0] - row[x])\n        Torder.append(i)\n    \n    return Torder\n\n# Assembling helper functions\ndef generatematrix(row):\n  \n  # Make Torder\n  Torder = make_torder(row)\n  \n  # Printing Matrix\n  \n  print(f\"X  I{' I'.join(str(el) for el in row)} \\\n  X\".replace('10', 'T').replace('11', 'E'))\n  \n  for x in Torder:\n      transpose_print(row, x)\n      \n  print(f\"X  RI{'RI'.join(str(el) for el in row)}\\\n  X\".replace('10', 'T').replace('11', 'E'))\n\nif __name__ == \"__main__\":\n    myrow = [2, 11, 6, 5, 4, 3, 0, 8, 9, 7, 1, 10]\n    \n    generatematrix(myrow)\n\nX  I2 IE I6 I5 I4 I3 I0 I8 I9 I7 I1 IT   X\nP2 [2, E, 6, 5, 4, 3, 0, 8, 9, 7, 1, T] R2\nP5 [5, 2, 9, 8, 7, 6, 3, E, 0, T, 4, 1] R5\nPT [T, 7, 2, 1, 0, E, 8, 4, 5, 3, 9, 6] RT\nPE [E, 8, 3, 2, 1, 0, 9, 5, 6, 4, T, 7] RE\nP0 [0, 9, 4, 3, 2, 1, T, 6, 7, 5, E, 8] R0\nP1 [1, T, 5, 4, 3, 2, E, 7, 8, 6, 0, 9] R1\nP4 [4, 1, 8, 7, 6, 5, 2, T, E, 9, 3, 0] R4\nP8 [8, 5, 0, E, T, 9, 6, 2, 3, 1, 7, 4] R8\nP7 [7, 4, E, T, 9, 8, 5, 1, 2, 0, 6, 3] R7\nP9 [9, 6, 1, 0, E, T, 7, 3, 4, 2, 8, 5] R9\nP3 [3, 0, 7, 6, 5, 4, 1, 9, T, 8, 2, E] R3\nP6 [6, 3, T, 9, 8, 7, 4, 0, 1, E, 5, 2] R6\nX  RI2RIERI6RI5RI4RI3RI0RI8RI9RI7RI1RIT  X\n\n\nThere you have it! Some places to take this next would be to make pitch class numbers and regular note spellings (like Bb) interchangeable, turning rows into a class with transposition as a method, a way to check that your input row is a correct possible row, MIDI playback, all kinds of things. But I hope that this was an interesting introduction. I’ve found combining my experience with music theory and coding to be very rewarding, so I want to thank you for reading this far!\nAny questions? Want some more weird music recommendations?? Find me on LinkedIn!"
  },
  {
    "objectID": "posts/2024-10-23-Roots-Chapter-Announcement/index.html",
    "href": "posts/2024-10-23-Roots-Chapter-Announcement/index.html",
    "title": "Publication Announcement!",
    "section": "",
    "text": "Taylor Ackley, a professor of music at Brandeis University, and I wrote a book chapter about our experience founding an American Roots music ensemble while we were grad students at Stony Brook University. We featured instruments from classical traditions and performers from jazz and chamber music backgrounds all playing folk music by ear. Check out one of our albums!\nWhile we were successful as a performing group on Long Island, our approach sometimes conflicted with typical instruction musicians receive in higher ed in America. Taylor and I told the stories of these conflicts through Taylor’s experience as a way of encouraging students to give this approach a try, and encouraging educators to challenge their own expectations about what makes a successful graduate-level ensemble. We got to write about a lot of things that are important to us, including the complicated history of American popular music, race, and class in the 20th century. I loved getting to write about my experience playing clarinet in church as a boy, and I love Taylor’s first line of the conclusion that reads:\n\n“This chapter has purposefully presented big questions without offering any real answers.” (!!!)\n\nCheck out the book here.\nI have to admit, it is a little bittersweet to be reading our chapter now since I decided to leave academia a little more than a year ago. Taylor and I drafted the proposal for this chapter in the summer of 2020, when many things about our lives weren’t certain. Publication can be a pivotal step in gaining seniority and better job placement as a college professor, so there is a kind of dull pain that runs alongside my sense of pride and accomplishment holding the book in my hands. Brainstorming about creative projects and collaborating on them are still some of my favorite things to do, and this last year has involved stretching these skills in new and unpredictable ways for me. But I will always be proud of Taylor and myself for our enduring friendship, the writing we’ve done together, and most importantly, the music."
  },
  {
    "objectID": "posts/2024-12-5-Score-Gmj/index.html#spitballing-on-linkedin",
    "href": "posts/2024-12-5-Score-Gmj/index.html#spitballing-on-linkedin",
    "title": "Musical Scores as Data Visualizations",
    "section": "Spitballing on LinkedIn",
    "text": "Spitballing on LinkedIn\nLast week, I was looking to put together a quick post for LinkedIn. It gets your profile to recruiters and hiring managers if you regularly post, hence why LinkedIn is full of repetitive plagiarist garbage. I’ve been thinking about data visualization a lot these days as part of my capstone project for NYC Data Science Academy. I was noticing that this project was scratching some creative itches like writing music does so I threw up a short post.\nI wanted to expand on what I was getting at in this post. I said that data visualization and writing music were very similar for me. In both, you’re trying to clearly convey information to an audience (the stats/kpis/metrics to the business decision-maker vs. the musical notation to the performer). Similarly in both, there’s a point in the process where you have to give over control to that audience for your work have any impact. At some point with the visualization, the proof of its quality has to be when it’s given to somebody in order to inform a business decision. A pretty graph is great and all, but what does it do?"
  },
  {
    "objectID": "posts/2024-12-5-Score-Gmj/index.html#showing-the-score",
    "href": "posts/2024-12-5-Score-Gmj/index.html#showing-the-score",
    "title": "Musical Scores as Data Visualizations",
    "section": "Showing the Score",
    "text": "Showing the Score\nI posted an excerpt of one of my scores as an example of a musical job I did where I was really proud of the technical work of visualizing the score. This is an excerpt of my piece Four Etudes on American Hymns for solo clarinet. I had to hide a lot of otherwise standard parts of music notation like time signatures and barlines to make it legible while featuring the dense variety of notation that’s here. Not to toot my own horn, but I really think this excerpt reflects a really subtle understanding of music notation software.\nWhat has been equal parts frustrating and energizing about my career now is that I don’t yet have this sort of subtle control over non-musical data visualization! I’ve had my fun with Seaborn and ggplot2 and I’m learning all the time, but I just know there are years of drilling with coding that I don’t share with some of my colleagues. I do believe that my background as a musician allows me a unique perspective on problem-solving and creativity that I can share with my non-musical data friends!\nCheck out my friend Sarah’s interpretation of what this excerpt should sound like. The excerpt in the score example above starts at 6:49. I was so moved by Sarah’s effort on my piece and her beautiful performance!"
  },
  {
    "objectID": "posts/2024-11-14-Eliza-Meetup/index.html#meeting-eliza",
    "href": "posts/2024-11-14-Eliza-Meetup/index.html#meeting-eliza",
    "title": "Pizza and Chatbots: Wouldn’t It Be Loverly!- Meeting ELIZA",
    "section": "Meeting Eliza",
    "text": "Meeting Eliza\nYesterday, I attended the second in a series of yearly events hosted by SUNY-Old Westbury. Professors and students from computer science, math, physics, and other areas came together to learn about the first chatbot, ELIZA, and see how the code in Python would work. Professor Frank Sanacory took us through ELIZA and we learned a lot!\nImagine being able to use a computer like a therapist. You type in things about what you’re feeling, and the computer responds in ways that a mental health professional might: asking you questions, prompting you to clarify or elaborate on what you’ve already said. This approach was pioneered by Joseph Weizenbaum in the 1960s. Take a look at a representative conversation from ELIZA (Eliza’s responses are in all caps).\n\nMen are all alike.\nIN WHAT WAY?\nThey’re always bugging us about something or other.\nCAN YOU THINK OF A SPECIFIC EXAMPLE?\nWell, my boyfriend made me come here.\nYOUR BOYFRIEND MADE YOU COME HERE?\nHe says I’m depressed much of the time.\nI AM SORRY TO HEAR YOU ARE DEPRESSED.\nIt’s true. I am unhappy.\nDO YOU THINK COMING HERE WILL HELP YOU NOT TO BE UNHAPPY.\nI need some help, that much seems certain.\nWHAT WOULD IT MEAN TO YOU IF YOU GOT SOME HELP?\nPerhaps I could learn to get along with my mother.\nTELL ME MORE ABOUT YOUR FAMILY.\nMy mother takes care of me.\nWHO ELSE IN YOUR FAMILY TAKES CARE OF YOU?\nMy father.\nYOUR FATHER?\nYou are like my father in some ways.\nWHAT RESEMBLANCE DO YOU SEE?\nYou are not very aggressive, but I think you don’t want me to notice that.\nWHAT MAKES YOU THINK I AM NOT VERY AGGRESSIVE?\nYou don’t argue with me.\nWHY DO YOU THINK I DON’T ARGUE WITH YOU?\nYou are afraid of me.\nDOES IT PLEASE YOU TO BELIEVE I AM AFRAID OF YOU?\nMy father is afraid of everybody.\nWHAT ELSE COMES TO YOUR MIND WHEN YOU THINK OF YOUR FATHER?\nBullies.\nDOES THAT HAVE ANYTHING TO DO WITH THE FACT THAT YOUR BOYFRIEND MADE YOU COME HERE?\n\nWeizenbaum, Joseph “ELIZA – A Computer Program For the Study of Natural Language Communication Between Man and Machine” in: Communications of the ACM; Volume 9, Issue 1 (January 1966): p 36-45."
  },
  {
    "objectID": "posts/2024-11-14-Eliza-Meetup/index.html#rules-for-interacting",
    "href": "posts/2024-11-14-Eliza-Meetup/index.html#rules-for-interacting",
    "title": "Pizza and Chatbots: Wouldn’t It Be Loverly!- Meeting ELIZA",
    "section": "Rules for Interacting",
    "text": "Rules for Interacting\nThere’s a story that I can’t find online anymore about how the great opera singer Enrico Caruso had to pass himself off as knowing a lot more languages than he actually knew to make it in the opera world, so he would just parrot the last few words anyone said to him in a conversation to make it seem like he knew what was going on. Not the most bracing chat, but it would do in a pinch.\n\n\n\n‘I’m tired so I’m taking the rest of the night off.’ ‘Taking the rest of the night off, huh?’\n\n\nCaruso’s strategy was a basic rule to respond to other people talking without giving away that he didn’t really know what was going on. Start stacking a few rules like this on top of each other and you get a chatbot. With some time with this dialogue, we could brainstorm some of the patterns and functions that ELIZA uses to respond to input in a human-like way:\n\nWhen a user says “always,” ask them to give you an example.\n\nWhen a user mentions their family, ask them to tell you more about their family.\n\nIf the user says a phrase with “I” or “you”, flip it to “you” or “I” and rephrase it back.\n\nThere’s obviously a lot more going on here, but we can already see some steps falling into place with these guidelines."
  },
  {
    "objectID": "posts/2024-11-14-Eliza-Meetup/index.html#why-eliza",
    "href": "posts/2024-11-14-Eliza-Meetup/index.html#why-eliza",
    "title": "Pizza and Chatbots: Wouldn’t It Be Loverly!- Meeting ELIZA",
    "section": "Why Eliza?",
    "text": "Why Eliza?\nBefore we talk a little Python, I have to briefly tell you about why this chatbot was named ELIZA. “She” is named for Eliza Doolittle, the filthy cockney flower salesgirl in George Bernard Shaw’s “Pygmalion”, who through a grueling series of speaking exercises led by Dr. Henry Higgins, passes herself off at a high-society ball as a Hungarian princess. In the same way that her repeated exercises made her a better speaker, Weizenbaum noticed that repeated use and input from multiple users refined ELIZA’s performance in a similar way. I know Eliza Doolittle from the musical adaptation, “My Fair Lady”- notice her incredible transformation throughout!\n\n\n\nI’ll take any excuse to fawn over Audrey Hepburn."
  },
  {
    "objectID": "posts/2024-11-14-Eliza-Meetup/index.html#preliminary-python--string-manipulation",
    "href": "posts/2024-11-14-Eliza-Meetup/index.html#preliminary-python--string-manipulation",
    "title": "Pizza and Chatbots: Wouldn’t It Be Loverly!- Meeting ELIZA",
    "section": "Preliminary Python- String Manipulation",
    "text": "Preliminary Python- String Manipulation\nProfessor Sanacory took us through some of the Python we would need to make our own version of Eliza. We have to really get right with string manipulation, as the human input will be typed in in a string format. Two techniques he suggested included making all your code only deal with lowercase text and changing the user input to lowercase before you do anything with it. Another technique is to take the human input and break it up into a list of words so you can isolate words that would cue the bot like “family”, “father”, “always”, “I”, “you”, or others!\n\nimport string\n\ndef lower_split(mystring):\n  # Takes in string input from human. \n  # Converts to lowercase, removes punctuation, then \n  # splits into a list of strings representing each word\n  \n  mystring = mystring.lower()\n  nopunct = mystring.translate(str.maketrans('', '', string.punctuation))\n  print(nopunct.split(\" \"))\n\nlower_split(\"I LOve My FaIr LADY.\")\n\n['i', 'love', 'my', 'fair', 'lady']\n\n\nYou can start imagining next steps, right? Eliminating redundant spaces, keeping question marks in the input, and overall, working to standardize the input as much as possible so differences between how different people type get flattened out."
  },
  {
    "objectID": "posts/2024-11-14-Eliza-Meetup/index.html#next-steps",
    "href": "posts/2024-11-14-Eliza-Meetup/index.html#next-steps",
    "title": "Pizza and Chatbots: Wouldn’t It Be Loverly!- Meeting ELIZA",
    "section": "Next Steps?",
    "text": "Next Steps?\nI’m not just going to copy and paste the bot code in here. That wouldn’t be fun. I want to sit with the code we looked at yesterday and try to make it my own. I think it would be fun to make a bot that responds not like Eliza Doolittle, but Henry Higgins, the flamboyant and impatient bachelor flinging insults, asking for his slippers, and criticizing any of your mistakes in written English. Or a chatbot that isn’t particularly good at its job, peppering in truisms like “It is what it is.” or “That’s showbiz, baby.” My wife mentioned that the ELIZA exchange sounded like a Meisner technique acting exercise where actors repeat each other’s words, so maybe there’s something in there to explore too. I have a couple other projects going on, so this will probably have to wait for Christmas break, but it’s always fun to start thinking about a new project!"
  },
  {
    "objectID": "posts/2024-10-16-ACCET-Presentation/index.html",
    "href": "posts/2024-10-16-ACCET-Presentation/index.html",
    "title": "ACCET Faculty Professional Development Day Wrap-Up",
    "section": "",
    "text": "It was surreal to get to present alongside Vivian Zhang as part of the ACCET Faculty Professional Development Day last week. ACCET is an accrediting body focusing on continuing education and accredits NYC Data Science Academy. As somebody who has spent a great deal of time in the classroom and on Zoom presentations like this, it was fun to get back into my element and present!\nVivian’s introduction to AI was superb, but what I found most impressive about her presentation was her ability to respond extemporaneously to questions from the Zoom chat. The chat had about 125 participants, and a lot of them had questions they wanted answered! The chat was full of educators, so lots of questions centered around plagiarism and how to hold students to a meaningful standard despite the power of generative AI. There were questions about Tesla, housekeeping robots, what work AI should be doing, and many more.\nIn my portion of the presentation, I spoke about a use case for AI in an educational setting, namely Articulate.AI where I interned this summer, and am now on a contract as a Pre-Sales Data Scientist. After the flurry of questions about all of AI’s capabilities, I honed in on a specific use case of AI as a way of streamlining the work of an admissions or enrollment office. As an educator, I found myself sending lots of emails to students with the same exact information over and over. This bot could automate a lot of that work, but more importantly, tailor its approach to students by asking them questions and even giving them recommendations. It was very cool to show off some of what makes the bot work to a big group of educators, and I had a great time.\n\n\n\nJust a little snippet of what I showed. Click Articulate’s link to see more!\n\n\nThank you to Vivian for this opportunity! Her mentorship has been incredible and I am very grateful :)."
  },
  {
    "objectID": "portfolio.html",
    "href": "portfolio.html",
    "title": "Portfolio",
    "section": "",
    "text": "Check out my projects, detailing proficiency in data visualization, predictive modeling, Python, R, and SQL."
  },
  {
    "objectID": "portfolio.html#understanding-the-magnificent-seven",
    "href": "portfolio.html#understanding-the-magnificent-seven",
    "title": "Portfolio",
    "section": "Understanding The Magnificent Seven",
    "text": "Understanding The Magnificent Seven\nInteractive dashboard in R/Shiny examining the “Magnificent Seven” stocks while comparing their performance to the S&P 500. While avoiding giving investing advice, I illustrate the Seven’s outsize share of the S&P’s total market cap, suggesting that these companies’ performances (boosted by Covid-19 and the craze for AI) are inflating the S&P’s overall performance.\nIn the app, you can customize several visualizations of the Mag7 stocks and their performance compared to the S&P.\n\n\n\n\n\n\n\n\nMonthly averaged price data from 2015 to 2024.\n\n\n\n\n\nPercent change in META price compared to the S&P 500 from 2022 to present. Both values were negative until early 2024.\n\n\n\n\n\nAt year end of 2023, the Seven accounted for a quarter of the S&P 500’s $47.7 trillion market cap.\n\n\n\n\n\nBar chart of S&P 500’s market cap from year-end 2014. The considerable contraction in 2022 is part of a larger stock market decline in 2022 due to the aftermath of Covid and the Russian invasion of Ukraine.\n\n\nThe app is hosted here, the code is here, and a blog post discussing the project in further detail is here.\nMy talk begins at 0:36."
  },
  {
    "objectID": "portfolio.html#predicting-real-estate-prices-using-machine-learning",
    "href": "portfolio.html#predicting-real-estate-prices-using-machine-learning",
    "title": "Portfolio",
    "section": "Predicting Real Estate Prices Using Machine Learning",
    "text": "Predicting Real Estate Prices Using Machine Learning\nImplemented multiple machine learning models in Python and Scikit-learn to predict house prices using the Ames dataset from Kaggle. The process involved data cleaning and preparation, feature engineering, preprocessing, and modeling. Models included Linear Regression, Penalized Linear Regression, Support Vector Machines, Random Forests, and Gradient Boosting.\nMy approach highlighted the trade-offs between accuracy and interpretability in ML models. Multiple Linear Regression was my endpoint of interpretability over accuracy, while Gradient Boosting was my endpoint of accuracy over interpretability. By doing a deep dive on these two models, I illustrate the endpoints of accessibility and accuracy in order to inform realtors and home buyers and sellers about the best ways to approach the real estate market. My analysis suggests that big factors like square footage and number of bedrooms and bathrooms factors into home prices, but preparing the data with subtler interactions like “rooms multiplied by bedrooms” can help ML models discover deeper differences between similar homes and yield more accurate sale price predictions.\n\n\n\nAs ML models increase in accuracy, they decrease in interpretability, and vice versa.\n\n\n\n\n\nSimple Linear Regression: Highly Interpretable, but less accurate than other models.\n\n\n\n\n\nGradient Boosting: Highly Accurate, but less interpretable than other models.\n\n\nMy code can be found here and a blog post discussing the project in further detail is here.\nMy talk begins at 0:35."
  },
  {
    "objectID": "portfolio.html#words-to-learn-to-solve-the-new-york-times-crossword-puzzle",
    "href": "portfolio.html#words-to-learn-to-solve-the-new-york-times-crossword-puzzle",
    "title": "Portfolio",
    "section": "Words to Learn to Solve the New York Times Crossword Puzzle",
    "text": "Words to Learn to Solve the New York Times Crossword Puzzle\nThis analysis is targeted towards people who have done some crossword puzzles but want to take their efforts more seriously and improve their game. While simply practicing doing crossword puzzles consistently is obviously a great way to improve, analysis on a dataset containing all the clues and answers from NYT puzzles between 1993-2021 reveals some trends about the words that commonly feature so that players can study them away from the puzzles and speed up their improvement.\nAfter some descriptive analysis of the dataset using Python, including examining missing values and some feature engineering involving word length, days of the week, and vowel ratios of the words. After briefly analyzing the most-common clues, I make a list of the most commonly-featured words in these puzzles. This list isn’t a great study tool, though, because a lot of these words are already known to the average English-language speaker.\nSo, I cross-reference this list with a second list, 5,050 of the most common and currently-used words in the English language. By eliminating these words from the puzzle list, I create a valuable study guide: a list of words that are both common in the NYT Crossword puzzle, but are perhaps not known to the average person starting out.   My code can be found here and a blog post discussing the project in further detail is here.\nThanks for taking a look!"
  }
]